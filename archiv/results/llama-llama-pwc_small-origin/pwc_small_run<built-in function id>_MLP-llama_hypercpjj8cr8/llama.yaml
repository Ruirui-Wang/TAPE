accelerator: auto
cfg_dest: llama.yaml
data:
  device: cuda:0
  include_negatives: true
  method: w2v
  name: pwc_small
  split_index:
  - 0.8
  - 0.15
  - 0.05
  split_labels: true
  test_pct: 0.05
  undirected: true
  val_pct: 0.15
device: cuda:0
embedder:
  type: llama
metric_best: acc
model:
  device: cuda:0
  dropout: 0.1
  hidden_channels: 128
  num_layers: 3
  type: MLP-llama
num_threads: 11
optimizer:
  base_lr: 0.001
  type: adam
  weight_decay: 0.0005
out_dir: results/llama-llama-pwc_small-origin
params: 541057
print: file
run:
  multiple_splits: None
  num_threads: 11
  seed: 0
run_dir: results/llama-llama-pwc_small-origin/pwc_small_run<built-in function id>_MLP-llama_hypercpjj8cr8
run_id: 1
seed: 1
train:
  auto_resume: false
  batch_size: 1024
  device: 0
  epochs: 30
  eval_period: 1
  final_eval: false
  finetune: false
  mode: custom
wandb:
  name_tag: pwc_small_run<built-in function id>_MLP-llama_hypercpjj8cr8
  project: gtblueprint
  use: true
